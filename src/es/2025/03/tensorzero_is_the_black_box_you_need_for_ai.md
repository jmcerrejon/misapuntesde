---
title: TensorZero es la caja negra que necesitas para IA
icon: fa-solid fa-code
author: Jose Cerrejon
date: 2025-03-29
category:
    - Developer
tags:
    - AI
    - LLM
---

# TensorZero es la caja negra que necesitas para IA

![TensorZero Dashboard](/images/2025/03/tensonzero_01.png "TensorZero Dashboard")

Actualmente estoy trabajando en un proyecto que explora las capacidades de la _arquitectura GenAI_ y sus aplicaciones en varios campos. Estamos utilizando recursos de alto nivel como _AWS_ y sus servicios como _Bedrock, Lambdas, StepFunctions_ y otros para crear una arquitectura robusta y escalable (o eso decimos).

Est√° bien para una arquitectura de alto nivel donde puedes usar todos esos servicios algo carillos, pero... ¬øQu√© pasa si quieres crear un proyecto de IA de bajo/medio nivel que pueda ser utilizado en cualquier entorno? _Amy Chen_ se puso en contacto conmigo para presentarme _TensorZero_, y hoy voy a mostrarte c√≥mo lo he usado en un peque√±o ejemplo.

## ¬øQu√© es TensorZero?

![Diagrama](/images/2025/03/tensonzero_02.png "Diagrama de componentes")

_TensorZero_ crea un bucle de retroalimentaci√≥n para optimizar aplicaciones _LLM_, convirtiendo datos de producci√≥n en modelos m√°s inteligentes, r√°pidos y econ√≥micos. Es una caja negra que te permite crear y entrenar tus propios modelos sin necesidad de recursos costosos. Est√° dise√±ado para ser f√°cil de usar e integrar en tus proyectos existentes... Y s√≠, antes de que preguntes: **Es open-source y algunos de sus componentes est√°n escritos en Rust.**

-   Integra nuestro gateway de modelos.
-   Env√≠a m√©tricas o retroalimentaci√≥n.
-   Optimiza prompts, modelos y estrategias de inferencia.
-   Observa c√≥mo tus LLMs mejoran con el tiempo.

Al final, proporciona un ciclo de datos y aprendizaje para LLMs unificando:

-   Inferencia: una API para todos los LLMs, con <1ms P99 de sobrecarga.
-   Observabilidad: inferencia y retroalimentaci√≥n ‚Üí tu base de datos.
-   Optimizaci√≥n: desde prompts hasta ajuste fino y RL.
-   Experimentaci√≥n: pruebas A/B integradas, enrutamiento, alternativas.

Genial, ¬øVerdad? Pero, ¬øC√≥mo se usa? Veamos un ejemplo sencillo de c√≥mo usarlo en tus propios proyectos.

## C√≥mo usar TensorZero

Voy a probar la biblioteca _TensorZero_ con un ejemplo que genera un pseudo-resumen. La idea es crear una funci√≥n sencilla que nos diga qu√© es _TensorZero_. La funci√≥n se llamar√° `generate_summarizer` y usar√° el modelo `gpt-4o-mini`.

Seg√∫n la _documentaci√≥n de inicio r√°pido_, necesito un archivo llamado `tensorzero.toml` con una configuraci√≥n m√≠nima:

```toml ./config/tensorzero.toml
# Una funci√≥n define la tarea que estamos abordando (por ejemplo, generar un resumen)...
[functions.generate_summarizer]
type = "chat"

# Dado que solo tenemos una variante para esta funci√≥n, el gateway siempre la usar√°.
[functions.generate_summarizer.variants.gpt_4o_mini]
type = "chat_completion"
model = "openai::gpt-4o-mini"
```

¬°Ah! Necesitas configurar/exportar una variable de entorno para `OPENAI_API_KEY` con tu clave API.

Ahora descarga el siguiente archivo [docker-compose.yaml](https://raw.githubusercontent.com/tensorzero/tensorzero/refs/heads/main/examples/quickstart/docker-compose.yml) y ejec√∫talo:

```sh
docker-compose up
```

:::warning
No uses ese docker-compose.yaml en producci√≥n. Para despliegues listos para producci√≥n, consulta: [https://www.tensorzero.com/docs/gateway/deployment](https://www.tensorzero.com/docs/gateway/deployment).
:::

![Deploying the container](/images/2025/03/tensonzero_03.jpg "Deploying the container")

Puedes interactuar con el _TensorZero Gateway_ de varias maneras: usando el cliente _TensorZero Python_, aprovechando los clientes existentes de _OpenAI_ (disponibles para _Python, Node.js_ y otros lenguajes), o directamente a trav√©s de su _API HTTP_, lo que lo hace accesible desde cualquier lenguaje de programaci√≥n.

Voy a usar la implementaci√≥n b√°sica en _Python_, as√≠ que necesito instalar el paquete `tensorzero`. Vamos a hacerlo usando [uv](https://docs.astral.sh/uv/), pero puedes usar cualquier gestor de paquetes que desees. Abre un nuevo terminal y ejecuta los siguientes comandos:

```sh
uv init .
uv add tensorzero
```

![Adding package and virtual environment](/images/2025/03/tensonzero_04.jpg "Adding package and virtual environment")

Ahora puedo crear un script sencillo para generar un resumen. El script se ver√° as√≠ y debe tener el nombre `after.py`:

```python ./after.py
from tensorzero import TensorZeroGateway

with TensorZeroGateway.build_embedded(
    clickhouse_url="http://chuser:chpassword@localhost:8123/tensorzero",
    config_file="config/tensorzero.toml",
) as client:
    response = client.inference(
        function_name="generate_summarizer",
        input={
            "messages": [
                {
                    "role": "user",
                    "content": "Summarize the key features of TensorZero.",
                }
            ]
        },
    )

print(response)
```

Ahora ejecuta el script:

```sh
export OPENAI_API_KEY=your_openai_api_key
uv run after.py
```

Este es el resultado que obtienes:

```sh
ChatInferenceResponse(
    inference_id=UUID('0195e199-9227-76b3-a96b-f042cf892917'),
    episode_id=UUID('0195e199-9227-76b3-a96b-f05bb3aec0d3'),
    variant_name='gpt_4o_mini',
    content=[
        Text(
            type='text',
            text='TensorZero is an advanced machine learning platform designed to accelerate the development and deployment of AI models. Here are the key features:\n\n1. **Model Development**: TensorZero offers intuitive tools for building and training machine learning models, making it accessible to users with varying levels of expertise.\n\n2. **Scalability**: The platform is designed to handle large datasets and complex models, enabling users to scale their projects efficiently.\n\n3. **Interoperability**: TensorZero can seamlessly integrate with various data sources and existing frameworks, allowing for flexibility in workflow and data management.\n\n4. **Real-time Collaboration**: It supports collaborative features, enabling teams to work together in real time on projects.\n\n5. **Monitoring and Visualization**: The platform includes tools for monitoring model performance and visualizing data, which helps in understanding and optimizing models.\n\n6. **Deployment Options**: TensorZero provides various deployment options, facilitating the launch of models in different environments, whether on-premises or in the cloud.\n\n7. **User-friendly Interface**: A user-friendly design simplifies navigation and enhances the user experience, catering to both novice and experienced users.\n\n8. **Customizable Workflows**: Users can create customized workflows to fit specific project needs, enhancing efficiency and productivity.\n\nTensorZero aims to streamline the machine learning lifecycle, from development to deployment, while ensuring ease of use and adaptability.',
            arguments=None
        )
    ],
    usage=Usage(
        input_tokens=17,
        output_tokens=276
    ),
    finish_reason=<FinishReason.STOP: 'stop'>
)
```

¬°No est√° mal! El generador de res√∫menes funciona como puedes apreciar en la terminal. Tambi√©n se ven los tokens de entrada y salida utilizados en la solicitud, lo cual es √∫til para monitorear y optimizar tu uso de la _API de OpenAI_. Tambi√©n puedes ver el _inference_id_ y el _episode_id_, que son √∫tiles para rastrear las solicitudes y respuestas en el sistema _TensorZero_.

¬øRecuerdas el contenedor _Docker_ que iniciamos? Ve a http://localhost:4000 y puedes ver el tablero de _TensorZero UI_.

![Supervised Fine-tuning](/images/2025/03/tensonzero_05.png "Supervised Fine-tuning")

Podemos acceder a las pesta√±as de _Observability_ y _Optimization_. La pesta√±a de _Observability_ muestra _Inferences, Episodes y Functions_. La pesta√±a de _Optimization_ muestra una caracter√≠stica interesante: **Supervised Fine-tuning**. Este super-poder te permite mejorar el rendimiento de tu modelo proporcion√°ndole informaci√≥n adicional como puedes ver arriba. Una vez que comencemos a usar funciones m√°s avanzadas como retroalimentaci√≥n y variantes, la interfaz de observabilidad nos permitir√° rastrear m√©tricas, experimentos (pruebas A/B) y m√°s.

Esto fue solo una llamada a su biblioteca como puedes ver. Tienes m√°s tutoriales (¬°Un chatbot!) en la [documentaci√≥n de TensorZero](https://www.tensorzero.com/docs/gateway/tutorials), donde puedes explorar m√°s caracter√≠sticas y funcionalidades.

## Palabras finales

Este ejemplo es una peque√±a muestra de lo que _TensorZero_ es capaz de hacer. Espero tener tiempo para profundizar en sus caracter√≠sticas y funcionalidades en el futuro. üí™

Dije que puedes construir proyectos de bajo/medio nivel, pero creo que tambi√©n puedes construir proyectos grandes. Te permite crear y entrenar tus propios modelos sin necesidad de gastar mucho en recursos, y eso es una gran ventaja para los desarrolladores que quieran crear sus propias aplicaciones de IA sin necesidad de servicios en la nube. Me gusta que est√© dise√±ado para ser f√°cil de usar e integrar en proyectos nuevos o existentes, as√≠ que... ¬øQu√© est√°s esperando? ¬°Adelante, pru√©balo! Puedes encontrar la documentaci√≥n [aqu√≠](https://www.tensorzero.com/docs).

Gracias nuevamente a _Amy Chen_ por mostrarme _TensorZero_. Espero que encuentres este art√≠culo √∫til y que te ayude a crear tus propias aplicaciones de IA con _TensorZero_. Si tienes alguna pregunta o comentario, no dudes en contactarme via X-Twitter/LinkedIn/Email.
